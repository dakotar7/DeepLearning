{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982805dc",
   "metadata": {},
   "source": [
    "# Lesson 1: Introduction to Neural Networks\n",
    "\n",
    "## Classification Problems\n",
    "The most basic idea of a neural network (or ML in general) is the idea of classifying data by drawing a line through it to separate two different outcomes, then using that line to predict the result of a new input.\n",
    "\n",
    "## Linear Boundaries\n",
    "We can define our simple model as a linear equation, generalized as:\n",
    "$$\n",
    "w_1 x_1 + w_2 x_2 + b = 0\n",
    "$$\n",
    "\n",
    "We can vectorize this problem like so:\n",
    "\n",
    "$$\n",
    "\\overline{W}\\overline{x} + b = 0\n",
    "$$\n",
    "\n",
    "Where we define $\\overline{W} = (w_1, w_2)$ and $\\overline{x} = (x_1, x_2)$. We will define the label as $y$, and the prediction as $\\hat{y}$.\n",
    "\n",
    "**Prediction:**\n",
    "$$\n",
    "\\hat{y} = \\begin{cases}\n",
    "    1 & \\text{ if $\\overline{W}\\overline{x} + b \\ge 0$}\\\\\n",
    "    0 & \\text{ if $\\overline{W}\\overline{x} + b < 0$}\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "If we wanted to generalize even further, we can have $n$ number of variables and weights in the form of:\n",
    "\n",
    "$$\n",
    "w_1 x_1 + w_2 x_2 + ... + w_n x_n + b = 0\n",
    "$$\n",
    "\n",
    "where we can still use the same vector notation to denote this. Now, we are dealing with a hyperplane that cannot be graphically visualized. The hyperplane of any given data set will have $n-1$ dimensions, where $n$ is the dimensions of the data.\n",
    "\n",
    "## Perceptron\n",
    "\n",
    "Building block of NN. Is a graph that has **nodes** and **edges**. \n",
    "\n",
    "On the left we have $n$ inputs coming in, with values $x_1$ to $x_n$ (and $1$ in the last place). Then we have edges with weights $W_1$ to $W_n$ and $b$ (for the bias). The node takes these inputs and calculates a linear equation:\n",
    "\n",
    "$$\n",
    "Wx+b = \\sum_{i=1}^{n} W_i X_i + b\n",
    "$$\n",
    "\n",
    "The node then checks if the value is greater than or equal to zeroâ€”returning a value of **Yes** if it is and **No** if it is not.\n",
    "\n",
    "### Perceptrons as Logical Operators\n",
    "\n",
    "#### **AND** Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a558abe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:57:32.977087Z",
     "start_time": "2022-03-25T04:57:32.944466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      " Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "       0          0                  -1.5                    0          Yes\n",
      "       0          1                  -0.5                    0          Yes\n",
      "       1          0                  -0.5                    0          Yes\n",
      "       1          1                   0.5                    1          Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 1\n",
    "weight2 = 1\n",
    "bias = -1.5\n",
    "\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, False, False, True]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5477dfcb",
   "metadata": {},
   "source": [
    "#### **OR** Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc92ecdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:59:40.936992Z",
     "start_time": "2022-03-25T04:59:40.904653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      " Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "       0          0                  -0.7                    0          Yes\n",
      "       0          1                   0.3                    1          Yes\n",
      "       1          0                   0.3                    1          Yes\n",
      "       1          1                   1.3                    1          Yes\n"
     ]
    }
   ],
   "source": [
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 1\n",
    "weight2 = 1\n",
    "bias = -0.7\n",
    "\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, True, True, True]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c535850",
   "metadata": {},
   "source": [
    "#### **NOT** Operator\n",
    "\n",
    "Unlike the other perceptrons we looked at, the NOT operation only cares about one input. The operation returns a `0` if the input is `1` and a `1` if it's a `0`. The other inputs to the perceptron are ignored.\n",
    "\n",
    "In this quiz, you'll set the weights (`weight1`, `weight2`) and bias `bias` to the values that calculate the NOT operation on the second input and ignores the first input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b32ab33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T05:11:38.075879Z",
     "start_time": "2022-03-25T05:11:38.039833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      " Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "       0          0                   0.5                    1          Yes\n",
      "       0          1                  -0.5                    0          Yes\n",
      "       1          0                   0.5                    1          Yes\n",
      "       1          1                  -0.5                    0          Yes\n"
     ]
    }
   ],
   "source": [
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 0.0\n",
    "weight2 = -1.0\n",
    "bias = 0.5\n",
    "\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [True, False, True, False]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70fb6b4",
   "metadata": {},
   "source": [
    "#### **XOR** Operator\n",
    "\n",
    "The **XOR** can be created by layering the operators we have generated above in a specific pattern, namely:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f16970",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T05:45:31.228278Z",
     "start_time": "2022-03-25T05:45:31.206875Z"
    }
   },
   "source": [
    "`\n",
    "x1 ---------- **AND** ------ **NOT**\n",
    "  \\          /                      \\\n",
    "   \\        /                        \\\n",
    "    \\      /                          **XOR**\n",
    "     \\    /                          /\n",
    "      \\  /                __________/\n",
    "       \\/                /\n",
    "       /\\               /\n",
    "      /  \\             /\n",
    "     /    \\           /\n",
    "    /      \\         /\n",
    "   /        \\       /\n",
    "  /          \\     /\n",
    "x2           **OR**\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90969912",
   "metadata": {},
   "source": [
    "### Perceptron Trick\n",
    "\n",
    "After we guess at a linear equation to classify a set of points (a guess is always how we start), there will likley be misclassified points. We now need to tell the equation to move (or change) toward the misclassified points such that they an cross the boundary and become properly classified.\n",
    "\n",
    "To do this, we can apply an update rule to the perceptron equation: add (or subtract) the value of the misclassified point multiplied by a learning rate from the weights (with an added change to the bias) to move towards the point in steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c514f6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-26T05:55:20.982888Z",
     "start_time": "2022-03-26T05:55:20.975902Z"
    }
   },
   "outputs": [],
   "source": [
    "x1, x2 = 1, 1\n",
    "w1, w2, b = 3, 4, -10\n",
    "eq = w1*x1 + w2*x2 + b\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc19ccc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-26T05:55:21.577491Z",
     "start_time": "2022-03-26T05:55:21.559406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "503759bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-26T05:55:22.200545Z",
     "start_time": "2022-03-26T05:55:22.192315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -2.700000000000001\n",
      "2 -2.4000000000000012\n",
      "3 -2.1000000000000014\n",
      "4 -1.8000000000000025\n",
      "5 -1.5000000000000036\n",
      "6 -1.2000000000000028\n",
      "7 -0.9000000000000039\n",
      "8 -0.600000000000005\n",
      "9 -0.30000000000000604\n",
      "10 -7.105427357601002e-15\n",
      "11 0.29999999999999183\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "while eq < 0:\n",
    "    nw1, nw2, nb = w1+x1*alpha, w2+x2*alpha, b+alpha\n",
    "    eq = nw1*x1 + nw2*x2 + nb\n",
    "    count += 1\n",
    "    print(count, eq)\n",
    "    w1, w2, b = nw1, nw2, nb\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986ae120",
   "metadata": {},
   "source": [
    "### Perceptron Algorithm Pseudocode\n",
    "\n",
    "1. Start with random weights: $w_1, w_2, ... , w_n, b$\n",
    "2. For every misclassified point $x_1, ... , x_n$:\n",
    "  - If **prediction = 0**:\n",
    "    - For i = 1 ... n: $W_i = W_i + \\alpha x_i$\n",
    "    - Change the bias: $b = b + \\alpha$\n",
    "  - If **prediction = 1**:\n",
    "    - For i = 1 ... n: $W_i = W_i - \\alpha x_i$\n",
    "    - Change the bias: $b = b - \\alpha$\n",
    "    \n",
    "More formally, we can say that for a point with coordinates $(p,q)$, label $y$, and a prediction given by $\\hat{y} = step(w_1 x_1 + w_2 x_2 + b)$:\n",
    "- If the point is correctly classified, do nothing\n",
    "- If the point is classified positive, but it has a negative label, subtract $\\alpha p$, $\\alpha q$ and $\\alpha$ from $w_1$, $w_2$ and $b$ respectively.\n",
    "- If the point is classified negative, but it has a positive label, add $\\alpha p$, $\\alpha q$ and $\\alpha$ from $w_1$, $w_2$ and $b$ respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d18e892",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T06:03:54.727986Z",
     "start_time": "2022-03-27T06:03:54.663763Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Setting the random seed, feel free to change it and see different solutions.\n",
    "np.random.seed(42)\n",
    "\n",
    "def stepFunction(t):\n",
    "    if t >= 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def prediction(X, W, b):\n",
    "    return stepFunction((np.matmul(X,W)+b)[0])\n",
    "\n",
    "# TODO: Fill in the code below to implement the perceptron trick.\n",
    "# The function should receive as inputs the data X, the labels y,\n",
    "# the weights W (as an array), and the bias b,\n",
    "# update the weights and bias W, b, according to the perceptron algorithm,\n",
    "# and return W and b.\n",
    "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
    "    for i in range(len(X)):\n",
    "        yhat = prediction(X[i],W,b)\n",
    "        \n",
    "        if y[i]-yhat == 1:\n",
    "            W[0] += X[i][0]*learn_rate\n",
    "            W[1] += X[i][1]*learn_rate\n",
    "            b += learn_rate\n",
    "        if y[i]-yhat == -1:\n",
    "            W[0] -= X[i][0]*learn_rate\n",
    "            W[1] -= X[i][1]*learn_rate\n",
    "            b -= learn_rate\n",
    "    \n",
    "    return W, b\n",
    "    \n",
    "# This function runs the perceptron algorithm repeatedly on the dataset,\n",
    "# and returns a few of the boundary lines obtained in the iterations,\n",
    "# for plotting purposes.\n",
    "# Feel free to play with the learning rate and the num_epochs,\n",
    "# and see your results plotted below.\n",
    "def trainPerceptronAlgorithm(X, y, learn_rate = 0.05, num_epochs = 25):\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])\n",
    "    W = np.array(np.random.rand(2,1))\n",
    "    b = np.random.rand(1)[0] + x_max\n",
    "    # These are the solution lines that get plotted below.\n",
    "    boundary_lines = []\n",
    "    for i in range(num_epochs):\n",
    "        # In each epoch, we apply the perceptron step.\n",
    "        W, b = perceptronStep(X, y, W, b, learn_rate)\n",
    "        boundary_lines.append((-W[0]/W[1], -b/W[1]))\n",
    "    return boundary_lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4ab9d",
   "metadata": {},
   "source": [
    "## Non-Linear Classification\n",
    "\n",
    "In reality, we usually must use non-linear methods to properly classify data points.\n",
    "\n",
    "To do this effectively, we must utlized **Error Functions** in the form of *log-loss* error, and **Gradient Descent** to properly drive down our error. GD will find the minima for the necessarily *continuous* error function we will be generating.\n",
    "\n",
    "To get to a continuous error, we must change our classification system from a discrete step function to a continous Sigmoid function, defined below.\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be9aefec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T06:17:21.125778Z",
     "start_time": "2022-03-27T06:17:21.108498Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return 1/(1+np.e**(-x))\n",
    "\n",
    "def score(x1,x2):\n",
    "    return 4*x1 + 5*x2 - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06eac720",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T06:18:31.375589Z",
     "start_time": "2022-03-27T06:18:31.342018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.9999999943972036 8.315280276641327e-07 0.5\n"
     ]
    }
   ],
   "source": [
    "print(sigma(score(1,1)),sigma(score(2,4)),sigma(score(5,-5)),sigma(score(-4,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147473da",
   "metadata": {},
   "source": [
    "### Multiple Classes Problem\n",
    "\n",
    "If we are dealing with a Classification problem, the sigmoid function doesn't work as well for more than 2 classes. It turns out that we need to guarantee a few things:\n",
    "\n",
    "- The probabilities of getting all the classes sum to 1\n",
    "- We cannot have any negative numbers (see below)\n",
    "\n",
    "A simple way to get probabilities would be to take all the outputs from the classes, and divide each output by the sum of all outputs. But this presents an issue: If there are negative outputs, it is totally reasonable (given our linear scale here) that summing all the class outputs could give zero, and thus a divide by zero error. \n",
    "\n",
    "To get around this, we can use the exponential function $e^x$ to guarantee positive outputs for our classes. This also properly finds the probabilties of getting each class.\n",
    "\n",
    "Using $e^x$ like this is called the **Softmax Function**, and can be formally defined below:\n",
    "\n",
    "#### Softmax Function\n",
    "\n",
    "Let's say we have $n$ classes and a linear model that gives us a score for each of the classes:\n",
    "\n",
    "$$\n",
    "Z_1, ..., Z_n\n",
    "$$\n",
    "\n",
    "We can then turn these scores into probabilities. The probability that an object is in class $i$ will be:\n",
    "\n",
    "$$\n",
    "P(i) = \\frac{e^{Z_i}}{e^{Z_1} + ... + e^{Z_n}}\n",
    "$$\n",
    "\n",
    "This turns all our scores into probabilities that will sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9de3a7f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T06:40:00.007108Z",
     "start_time": "2022-03-27T06:39:59.989404Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Write a function that takes as input a list of numbers, and returns\n",
    "# the list of values given by the softmax function.\n",
    "def softmax(L):\n",
    "    L = np.array(L)\n",
    "    tot = np.sum(np.exp(L))\n",
    "    ans = np.exp(L) / tot\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39580580",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "\n",
    "When dealing with multiple classes, it becomes problematic to define how the data is to be represented numerically. In simpler problems where there are only two possible classes, a simple `1` and `0` can be used, but for multiple classes we can use a method called **One-Hot Encoding**, where we have a data column for each class (with the classes in the rows).\n",
    "\n",
    "| Animal | Duck? | Beaver? | Walrus? |\n",
    "|--------|-------|---------|---------|\n",
    "| Duck   | 1     | 0       | 0       |\n",
    "| Beaver | 0     | 1       | 0       |\n",
    "| Walrus | 0     | 0       | 1       |\n",
    "\n",
    "Now, a duck is classified numerically as 100, etc.\n",
    "\n",
    "## Maximum Likelyhood\n",
    "\n",
    "Now we look for a way to \"decide\" which model we would want to choose. The way we do this is an application of the probabilisitc nature of our models: i.e. we take advantage of the fact that the model will give a probability of a point being classified as one thing or as another thing. \n",
    "\n",
    "We can use these probability calculations, combined with knowing the true values of all the points, to use a method known as **Maximum Likelyhood** to calculate how \"good\" our model is.\n",
    "\n",
    "Any given model will tell us the probabilities that a given point belongs to each class. By using the actual class to choose the probability (according to the model) that the point is in that class, doing this for all the points, and multiplying all these probabilities together, we can get $P(all)$: the likelyhood that the model has classified all the points correctly (how good the model is). By maximizing this value, we can obtain the best model.\n",
    "\n",
    "Products, however, are hard when there are many points being multiplied together. Sums are better, so we can use the natural logarithm `ln` function and take advantage of the fact that $\\ln(a b) = \\ln(a) + \\ln(b)$ to turn our products into sums.\n",
    "\n",
    "Our probabilities will all be between 0 and 1, meaning the `ln` of anything will give a negative number. So the convention is to use the *negative sum of the natural logarithms* \n",
    "\n",
    "## Cross-Entropy\n",
    "\n",
    "Our probabilities will all be between 0 and 1, meaning the `ln` of anything will give a negative number. So the convention is to use the *negative sum of the natural logarithms*, we can define as the **Cross-Entropy** of the model.\n",
    "\n",
    "Due to the nature of this sum, we will see that:\n",
    "\n",
    "- Models with a **high** cross-entropy will be **bad**\n",
    "- Models with a **low** cross-entropy will be **good**\n",
    "\n",
    "Thus, the goal has now shifted from maximizing the probability to minimizing the cross-entropy.\n",
    "\n",
    "$$\n",
    "\\text{Cross-Entropy} = -\\sum_{i=1}^{m} y_i \\ln(p_i) + (1-y_i) \\ln(1-p_i)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f12f68b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T00:00:50.794829Z",
     "start_time": "2022-03-28T00:00:50.778289Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Write a function that takes as input two lists Y, P,\n",
    "# and returns the float corresponding to their cross-entropy.\n",
    "def cross_entropy(Y, P):\n",
    "    Y = np.float_(Y)\n",
    "    P = np.float_(P)\n",
    "    \n",
    "    s = np.sum(Y*np.log(P) + (1-Y)*np.log(1-P))\n",
    "    \n",
    "    return -s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a20909",
   "metadata": {},
   "source": [
    "## Multi-Class Cross-Entropy\n",
    "\n",
    "For multiple classes, we can define a new probability matrix $p_{ij}$ and a new labels matrix $y_{ij}$ and use them in a new CE formula:\n",
    "\n",
    "$$\n",
    "\\text{CE} = - \\sum_{i=1}^{n} \\sum_{j=1}^{m} y_{ij} \\ln(p_{ij})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc8d912",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Now we will work on a very popular and useful algorithm for machine learning, the logistic regression algorithm. It will:\n",
    "\n",
    "- Take your data\n",
    "- Pick a random model\n",
    "- Calculate the error\n",
    "- Minimize the error, and obtain a better model\n",
    "- Enjoy!\n",
    "\n",
    "### Error Function for binary classification problems\n",
    "\n",
    "With binary classification, the basic idea goes like this:\n",
    "\n",
    "- If $y = 1$\n",
    "\n",
    "  - $P(\\text{blue}) = \\hat{y}$\n",
    "\n",
    "  - $\\text{Error} = -\\ln(\\hat{y})$\n",
    "\n",
    "- If $y = 0$\n",
    "\n",
    "  - $P(\\text{red}) = 1-P(\\text{blue}) = 1 - \\hat{y}$\n",
    "\n",
    "  - $\\text{Error} = -\\ln(1-\\hat{y})$\n",
    "\n",
    "In all, we can say that $\\text{Error} = (1-y)\\ln(1-\\hat{y}) - y\\ln(\\hat{y})$\n",
    "\n",
    "More formally:\n",
    "\n",
    "$$\n",
    "\\text{Error funtion} = -\\frac{1}{m} \\sum_{i=1}^{m} (1-y_i)\\ln(1-\\hat{y_i}) + y_i\\ln(\\hat{y_i})\n",
    "$$\n",
    "\n",
    "### Full Error Function\n",
    "\n",
    "This incorporates the sigmoid function as a representation of the prediction $\\hat{y}$\n",
    "\n",
    "$$\n",
    "E(W,b) = -\\frac{1}{m} \\sum_{i=1}^{m} (1-y_i)\\ln(1-\\sigma(W x^{(i)} + b)) + y_i\\ln(\\sigma(W x^{(i)} + b))\n",
    "$$\n",
    "\n",
    "### Multiclass Error Function\n",
    "\n",
    "$$\n",
    "\\text{Error Function} = -\\frac{1}{m} \\sum_{i=1}^{m} \\sum_{j=1}^{n} y_{ij} \\ln(\\hat{y_{ij}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094da1c4",
   "metadata": {},
   "source": [
    "## Gradient Desent\n",
    "\n",
    "Let's start with an overview of Gradent Descent before we get into the mathematical details.\n",
    "\n",
    "Start with an initial guess of the prediction $\\hat{y}$:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\sigma(W x + b) \\leftarrow \\text{Bad}\n",
    "$$\n",
    "Which can be broken down into components as:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\sigma(w_1 x_n + ... + w_n x_n + b)\n",
    "$$\n",
    "We can next define the gradient of the Error Function as:\n",
    "\n",
    "$$\n",
    "\\nabla E = (\\frac{\\partial E}{\\partial w_1}, ... , \\frac{\\partial E}{\\partial w_n}, \\frac{\\partial E}{\\partial b})\n",
    "$$\n",
    "And the learning rate:\n",
    "\n",
    "$$\n",
    "\\alpha = 0.1\n",
    "$$\n",
    "And next we will have the update conditions for $w$ and $b$:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "w'_i & \\leftarrow w_i - \\alpha \\frac{\\partial E}{\\partial w_i} \\\\\n",
    "b' & \\leftarrow b - \\alpha \\frac{\\partial E}{\\partial b}\n",
    "\\end{split}\n",
    "$$\n",
    "To finally arrive at a much better prediction:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\sigma(W' x + b')\n",
    "$$\n",
    "\n",
    "### Gradient Calculation\n",
    "\n",
    "To start calculating the gradient of the error, we start with the derivative of the sigmoid function. Fortunately, it has a nice derivative:\n",
    "\n",
    "$$\n",
    "\\sigma'(x) = \\sigma(x) (1-\\sigma(x))\n",
    "$$\n",
    "\n",
    "Now recall, given a system of $m$ points labeled $x^{(1)}, ... , x^{(m)}$, the error formula is given by:\n",
    "\n",
    "$$\n",
    "E = -\\frac{1}{m} \\sum_{i=1}^{m} (y_i\\ln(\\hat{y_i}) + (1-y_i)\\ln(1-\\hat{y_i}))\n",
    "$$\n",
    "\n",
    "with a prediction given by $\\hat{y}_i = \\sigma(W x^{(i)} + b)$.\n",
    "\n",
    "Recall the gradient of $E$ is given by the partial derivatives\n",
    "\n",
    "$$\n",
    "\\nabla E = (\\frac{\\partial}{\\partial w_1} E, ... , \\frac{\\partial}{\\partial w_n} E, \\frac{\\partial}{\\partial b} E)\n",
    "$$\n",
    "\n",
    "For simplicity, we can consider just the error of any given single point, defined by:\n",
    "\n",
    "$$\n",
    "E =  - y\\ln(\\hat{y}) -(1-y)\\ln(1-\\hat{y})\n",
    "$$\n",
    "\n",
    "In order to calculate the derivative of this error with respect to the weights, we'll first calculate $\\frac{\\partial}{\\partial w_j} \\hat{y}$:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\frac{\\partial}{\\partial w_j} \\hat{y} & = \\frac{\\partial}{\\partial w_j} \\sigma(W x + b) \\\\\n",
    "& = \\sigma(W x + b)(1- \\sigma(W x + b)) \\bullet \\frac{\\partial}{\\partial w_j} (W x + b) \\\\\n",
    "& = \\hat{y}(1-\\hat{y}) \\bullet \\frac{\\partial}{\\partial w_j} (W x + b) \\\\\n",
    "& = \\hat{y}(1-\\hat{y}) \\bullet \\frac{\\partial}{\\partial w_j} (w_1 x_1 + ... + w_j x_j + ... + w_n x_n + b) \\\\\n",
    "& = \\hat{y}(1-\\hat{y}) \\bullet x_j\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "This last line is because the only non-constant term wrt $w_j$ is $w_j x_j$.\n",
    "\n",
    "Now we can calculate the derivative of the error $E$ at point $x$ wrt the weight $w_j$:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\frac{\\partial}{\\partial w_j} E & = \\frac{\\partial}{\\partial w_j} [-y\\ln(\\hat{y}) - (1-y)\\ln(1-\\hat{y})] \\\\\n",
    "& = -y \\frac{\\partial}{\\partial w_j} \\ln(\\hat{y}) - (1-y) \\frac{\\partial}{\\partial w_j} \\ln(1-\\hat{y}) \\\\\n",
    "& = -y \\cdotp \\frac{1}{\\hat{y}} \\cdotp \\frac{\\partial}{\\partial w_j} \\hat{y} - (1-y) \\cdotp \\frac{1}{1-\\hat{y}} \\cdotp \\frac{\\partial}{\\partial w_j} (1-\\hat{y})\\\\\n",
    "& = -y \\cdotp \\frac{1}{\\hat{y}} \\cdotp \\hat{y} (1-\\hat{y}) x_j - (1-y) \\cdotp \\frac{1}{1-\\hat{y}} \\cdotp (-1) \\hat{y} (1-\\hat{y}) x_j \\\\\n",
    "& = -y(1-\\hat{y}) \\cdotp x_j + (1-y) \\hat{y} \\cdotp x_j \\\\\n",
    "& = -(y-\\hat{y}) x_j\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "And similarly, it can be shown that:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial b} E = -(y-\\hat{y})\n",
    "$$\n",
    "\n",
    "This is important, and we can summarize this as follows:\n",
    "\n",
    "$$\n",
    "\\nabla E = -(y-\\hat{y})(x_1, ... , x_n, 1)\n",
    "$$\n",
    "\n",
    "\"If you think about it, this is fascinating. The gradient is actually a scalar times the coordinates of the point! And what is the scalar? Nothing less than a multiple of the difference between the label and the prediction. What significance does this have?\"\n",
    "\n",
    "If a point is well classified, we will get a small gradient. And if it's poorly classified, the gradient will be quite large.\n",
    "\n",
    "### Gradient Descent Step\n",
    "\n",
    "Based on the above information, we will update the weights with the following rules, after simplifying $w_i - \\alpha[-(y-\\hat{y}) x_i]$:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "w'_i & \\leftarrow w_i + \\alpha(y-\\hat{y}) x_i \\\\\n",
    "b' & \\leftarrow b + \\alpha(y-\\hat{y})\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "**Note**:\n",
    "\n",
    "Since we've taken the average of the errors, the term we are adding should be $\\frac{1}{m} \\cdot \\alpha$ instead of $\\alpha$, but as $\\alpha$ is a constant, then in order to simplify calculations, we'll just take $\\frac{1}{m} \\cdot \\alpha$ to be our learning rate, and abuse the notation by just calling it $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d0684",
   "metadata": {},
   "source": [
    "## Logistic Regression w/ Gradient Descent Algorithm\n",
    "\n",
    "Here are out steps for the logistic regression algorithm:\n",
    "\n",
    "1. Start with random weights: $w_1, ..., w_n, b$\n",
    "2. For every point $(x_1, ..., x_n)$:\n",
    "  - For $i = 1 ... n$:\n",
    "    - Update $w'_i \\leftarrow w_i - \\alpha (\\hat{y} - y)x_i$\n",
    "    - Update $b' \\leftarrow b - \\alpha (\\hat{y} - y)$\n",
    "3. Repeat until the error is small. \n",
    "\n",
    "This is like the perceptron algorithm!\n",
    "\n",
    "### Python Implementation (from GradientDescent notebook)\n",
    "\n",
    "Here is your turn to shine. Implement the following formulas, as explained in the text.\n",
    "- Sigmoid activation function\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "- Output (prediction) formula\n",
    "\n",
    "$$\\hat{y} = \\sigma(w_1 x_1 + w_2 x_2 + b)$$\n",
    "\n",
    "- Error function\n",
    "\n",
    "$$Error(y, \\hat{y}) = - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y})$$\n",
    "\n",
    "- The function that updates the weights\n",
    "\n",
    "$$ w_i \\longrightarrow w_i + \\alpha (y - \\hat{y}) x_i$$\n",
    "\n",
    "$$ b \\longrightarrow b + \\alpha (y - \\hat{y})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba6b8f85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T06:34:12.221359Z",
     "start_time": "2022-03-29T06:34:09.543285Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Activation (sigmoid) function\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Output (prediction) formula\n",
    "def output_formula(features, weights, bias):\n",
    "    wxb = np.matmul(features, weights) + bias\n",
    "    return sigmoid(wxb)\n",
    "\n",
    "# Error (log-loss) formula\n",
    "def error_formula(y, output):\n",
    "    return -y*np.log(output) - (1-y)*np.log(1-output)\n",
    "\n",
    "# Gradient descent step\n",
    "def update_weights(x, y, weights, bias, learnrate):\n",
    "    yhat = output_formula(x, weights, bias)\n",
    "    wprime = weights + learnrate*(y - yhat)*x\n",
    "    bprime = bias + learnrate*(y - yhat)\n",
    "    return wprime, bprime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af22e84",
   "metadata": {},
   "source": [
    "## Neural Networks: Non-Linear Models\n",
    "\n",
    "Basically, we can combine two or more previous linear models in a new linear combination to generate a final non-linear model of the data.\n",
    "\n",
    "Essentially the steps to do this are:\n",
    "\n",
    "- Calculate the probability for each model\n",
    "- Apply weights to the probabilities\n",
    "- Add the weighted probabilities\n",
    "- Apply the sigmoid function to the result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2e0efec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T06:34:14.702629Z",
     "start_time": "2022-03-29T06:34:14.686466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9168273035060777\n",
      "0.8807970779778823\n",
      "0.8021838885585818\n"
     ]
    }
   ],
   "source": [
    "def f(wb):\n",
    "    return sigmoid(wb[0]*0.4 + wb[1]*0.6 + wb[2])\n",
    "\n",
    "for wb in [[2,6,-2],[3,5,-2.2],[5,4,-3]]:\n",
    "    print(f(wb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e697ebc",
   "metadata": {},
   "source": [
    "## Feedforward Process\n",
    "\n",
    "Feedforward is the process neural networks use to turn the input into an output. In general terms, the process looks like this:\n",
    "\n",
    "- Take the input vector\n",
    "- Apply a sequence of linear models and sigmoid functions\n",
    "- Combine maps to create a highly non-linear map\n",
    "\n",
    "As we saw in the video, the feedforward formula is:\n",
    "\n",
    "$$\\hat{y}=\\sigma \\circ W^{(2)}\\circ\\sigma \\circ W^{(1)}(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d4b404",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "Now, we're ready to get our hands into training a neural network. For this, we'll use the method known as **backpropagation**. In a nutshell, backpropagation will consist of:\n",
    "\n",
    "- Doing a feedforward operation.\n",
    "- Comparing the output of the model with the desired output.\n",
    "- Calculating the error.\n",
    "- Running the feedforward operation backwards (backpropagation) to spread the error to each of the weights.\n",
    "- Use this to update the weights, and get a better model.\n",
    "- Continue this until we have a model that is good.\n",
    "\n",
    "## Lesson Review\n",
    "\n",
    "Congratulations on completing the lesson! In this lesson, we covered core foundational concepts in deep learning and neural networks, and then got some practice implementing gradient descent and backpropagation in Python. You've learned a ton in this lesson! If you followed along with everything, you now know the basics of how neural networks work and how they get trained!\n",
    "\n",
    "For your reference, here are the specific things you learned to do in this lesson:\n",
    "\n",
    "- Identify key characteristics of linear and non-linear classification problems.\n",
    "- Distinguish between classification problems based on the number of dimensions and classes required in the model.\n",
    "- Identify the key components of a perceptron and describe how perceptrons form the building blocks of neural networks.\n",
    "- Translate logical operators into perceptrons and vice versa.\n",
    "- Implement a simple perceptron algorithm in code to determine a linear boundary between two classes.\n",
    "- Adjust a simple perceptron algorithm so that it can generalize to non-linear boundaries.\n",
    "- Implement error functions and use them to perform gradient descent.\n",
    "- Distinguish between discrete vs continuous predictions, and use a sigmoid function to implement a continuous prediction.\n",
    "- Use softmax to implement continuous prediction and multi-class classification.\n",
    "- Encode non-numerical data as numerical data using one-hot encoding.\n",
    "- Use maximum likelihood, cross-entropy, and related probability calculations as a measure of classification model performance.\n",
    "- Apply logistic regression and gradient descent to minimize model error.\n",
    "- Identify the main components of neural networks and how they can be modified in different architectures.\n",
    "- Use backpropagation to improve the weights of a model for better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea5e0e",
   "metadata": {},
   "source": [
    "# Lesson 2: Implementing Gradient Descent\n",
    "\n",
    "## Gradient Descent with Squared Errors\n",
    "\n",
    "Common error metric: *Sum of Squared Errors*:\n",
    "\n",
    "$$E = \\frac{1}{2} \\sum_{\\mu} \\sum_{j} \\left[y_j^{\\mu} - \\hat{y}_j^{\\mu} \\right]^2$$\n",
    "\n",
    "where $\\hat{y}$ is the prediction and $y$ is the true value, and you take the sum over all output units $j$ and another sum over all data points $\\mu$. This might seem like a really complicated equation at first, but it's fairly simple once you understand the symbols and can say what's going on in words.\n",
    "\n",
    "First, the inside sum over $j$. This variable $j$ represents the output units of the network. So this inside sum is saying for each output unit, find the difference between the true value $y$ and the predicted value from the network $\\hat{y}$, then square the difference, then sum up all those squares.\n",
    "\n",
    "Then the other sum over $\\mu$ is a sum over all the data points. So, for each data point you calculate the inner sum of the squared differences for each output unit. Then you sum up those squared differences for each data point. That gives you the overall error for all the output predictions for all the data points.\n",
    "\n",
    "The SSE is a good choice for a few reasons. The square ensures the error is always positive and larger errors are penalized more than smaller errors. Also, it makes the math nice, always a plus.\n",
    "\n",
    "Remember that the output of a neural network, the prediction, depends on the weights\n",
    "\n",
    "$$\\hat{y}_j^{\\mu} = f \\left(\\sum_i w_{ij} x_i^{\\mu} \\right)$$\n",
    "\n",
    "and accordingly the error depends on the weights\n",
    "\n",
    "$$E = \\frac{1}{2} \\sum_{\\mu} \\sum_{j} \\left[y_j^{\\mu} - f \\left(\\sum_i w_{ij} x_i^{\\mu} \\right) \\right]^2$$\n",
    "\n",
    "Here, $f$ is the activation function. (this should be the sigmoid in the last lesson)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389227a0",
   "metadata": {},
   "source": [
    "### Simple Example\n",
    "\n",
    "Let's take and example for when the error is simply defined as \n",
    "\n",
    "$$E = \\frac{1}{2} \\left(y - \\hat{y} \\right)^2$$\n",
    "\n",
    "Then the partial of $E$ wrt $w_i$ will be:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\frac{\\partial E}{\\partial w_i} & = \\frac{\\partial}{\\partial w_i} \\frac{1}{2} \\left(y - \\hat{y} \\right)^2 \\\\\n",
    "& =  \\left(y - \\hat{y} \\right) \\frac{\\partial}{\\partial w_i} \\left(y - \\hat{y} \\right)\\\\\n",
    "& = -\\left(y-\\hat{y}\\right) \\frac{\\partial \\hat{y}}{\\partial w_i}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Recall that: $\\hat{y} = f(h)$ where $h = \\sum_i w_i x_i$, thus:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\frac{\\partial E}{\\partial w_i} & = -\\left(y-\\hat{y}\\right) \\frac{\\partial \\hat{y}}{\\partial w_i} \\\\\n",
    "& = -\\left(y-\\hat{y}\\right) f'(h) \\frac{\\partial}{\\partial w_i} \\sum w_i x_i\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "and in the case of the partial of the sum, we see that:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\frac{\\partial}{\\partial w_i} \\sum w_i x_i & = \\rightarrow \\\\\n",
    "\\text{Example:} \\ w_1 & = \\frac{\\partial}{\\partial w_1} [w_1 x_1 + w_2 x_2 +\\ ...\\ + w_n x_n] = x_1 + 0 + 0\\ +\\ ...\\\\\n",
    "\\therefore \\ \\frac{\\partial}{\\partial w_i} \\sum w_i x_i & = x_i\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "We then return to the derivative of $E$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial w_i} = -\\left(y-\\hat{y}\\right) f'(h) x_i\n",
    "$$\n",
    "\n",
    "And we can now define a step for the GD as:\n",
    "\n",
    "$$\n",
    "\\Delta w_i = \\eta\\left(y-\\hat{y}\\right) f'(h) x_i\n",
    "$$\n",
    "\n",
    "Similarly, we will also define an \"error term\":\n",
    "\n",
    "$$\n",
    "\\delta = \\left(y-\\hat{y}\\right) f'(h)\n",
    "$$\n",
    "\n",
    "Recalling that $h = \\sum w_i x_i$.\n",
    "\n",
    "So finally our GD step will be:\n",
    "\n",
    "$$\n",
    "w_i \\leftarrow w_i + \\eta \\delta x_i\n",
    "$$\n",
    "\n",
    "### Multiple Output Units:\n",
    "\n",
    "$$\n",
    "\\delta_j = \\left(y_j-\\hat{y_j}\\right) f'(h_j) \\\\\n",
    "\\Delta w_{ij} = \\eta \\delta_j x_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7365d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4b95733",
   "metadata": {},
   "source": [
    "## Gradient Descent: The Code\n",
    "\n",
    "Remember, $(y - \\hat y)$ is the output error, and $f'(h)$ refers to the derivative of the activation function, $f(h)$. We'll call that derivative the output gradient.\n",
    "\n",
    "Now I'll write this out in code for the case of only one output unit. We'll also be using the sigmoid as the activation function $f(h)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c702a8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T23:41:56.027199Z",
     "start_time": "2022-03-29T23:41:56.019822Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the sigmoid function for activations\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Derivative of the sigmoid function\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Input data\n",
    "x = np.array([0.1, 0.3])\n",
    "# Target\n",
    "y = 0.2\n",
    "# Input to output weights\n",
    "weights = np.array([-0.8, 0.5])\n",
    "\n",
    "# The learning rate, eta in the weight step equation\n",
    "learnrate = 0.5\n",
    "\n",
    "# the linear combination performed by the node (h in f(h) and f'(h))\n",
    "h = x[0]*weights[0] + x[1]*weights[1]\n",
    "# or h = np.dot(x, weights)\n",
    "\n",
    "# The neural network output (y-hat)\n",
    "nn_output = sigmoid(h)\n",
    "\n",
    "# output error (y - y-hat)\n",
    "error = y - nn_output\n",
    "\n",
    "# output gradient (f'(h))\n",
    "output_grad = sigmoid_prime(h)\n",
    "\n",
    "# error term (lowercase delta)\n",
    "error_term = error * output_grad\n",
    "\n",
    "# Gradient descent step \n",
    "del_w = [ learnrate * error_term * x[0],\n",
    "          learnrate * error_term * x[1]]\n",
    "# or del_w = learnrate * error_term * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac62d244",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T23:41:57.983603Z",
     "start_time": "2022-03-29T23:41:57.967777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network output:\n",
      "0.6899744811276125\n",
      "Amount of Error:\n",
      "-0.1899744811276125\n",
      "Change in Weights:\n",
      "[-0.02031869 -0.04063738 -0.06095608 -0.08127477]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    \"\"\"\n",
    "    # Derivative of the sigmoid function\n",
    "    \"\"\"\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "learnrate = 0.5\n",
    "x = np.array([1, 2, 3, 4])\n",
    "y = np.array(0.5)\n",
    "\n",
    "# Initial weights\n",
    "w = np.array([0.5, -0.5, 0.3, 0.1])\n",
    "\n",
    "### Calculate one gradient descent step for each weight\n",
    "### Note: Some steps have been consolidated, so there are\n",
    "###       fewer variable names than in the above sample code\n",
    "\n",
    "# TODO: Calculate the node's linear combination of inputs and weights\n",
    "h = np.matmul(x, w)\n",
    "\n",
    "# TODO: Calculate output of neural network\n",
    "nn_output = sigmoid(h)\n",
    "\n",
    "# TODO: Calculate error of neural network\n",
    "error = y - nn_output\n",
    "\n",
    "# TODO: Calculate the error term\n",
    "#       Remember, this requires the output gradient, which we haven't\n",
    "#       specifically added a variable for.\n",
    "error_term = error * sigmoid_prime(h)\n",
    "\n",
    "# TODO: Calculate change in weights\n",
    "del_w = learnrate*error_term*x\n",
    "\n",
    "print('Neural Network output:')\n",
    "print(nn_output)\n",
    "print('Amount of Error:')\n",
    "print(error)\n",
    "print('Change in Weights:')\n",
    "print(del_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edd0676",
   "metadata": {},
   "source": [
    "## Implementing Gradient Descent\n",
    "\n",
    "### Mean Squared Error\n",
    "\n",
    "We're going to make a small change to how we calculate the error here. Instead of the SSE, we're going to use the **mean** of the square errors (MSE). Now that we're using a lot of data, summing up all the weight steps can lead to really large updates that make the gradient descent diverge. To compensate for this, you'd need to use a quite small learning rate. Instead, we can just divide by the number of records in our data, mm to take the average. This way, no matter how much data we use, our learning rates will typically be in the range of 0.01 to 0.001. Then, we can use the MSE (shown below) to calculate the gradient and the result is the same as before, just averaged instead of summed.\n",
    "\n",
    "$$\n",
    "E = \\frac{1}{2 m} \\sum_{\\mu} \\left(y_{\\mu} + \\hat{y}^{\\mu} \\right)^2\n",
    "$$\n",
    "\n",
    "Here's the general algorithm for updating the weights with gradient descent:\n",
    "\n",
    "- Set the weight step to zero: $\\Delta w_i = 0$\n",
    "- For each record in the training data:\n",
    "  - Make a forward pass through the network, calculating the output $\\hat y = f\\left(\\sum_i w_i x_i \\right)$ \n",
    "  - Calculate the error term for the output unit, $\\delta = \\left(y - \\hat{y}\\right) * f'\\left(\\sum_i w_i x_i\\right)$\n",
    "  - Update the weight step $\\Delta w_i = \\Delta w_i + \\delta x_i$ \n",
    " - Update the weights $w_i = w_i + \\eta \\Delta w_i / m$ where $\\eta$ is the learning rate and mm is the number of records. Here we're averaging the weight steps to help reduce any large variations in the training data.\n",
    "- Repeat for $e$ epochs.\n",
    "\n",
    "You can also update the weights on each record instead of averaging the weight steps after going through all the records.\n",
    "\n",
    "Remember that we're using the sigmoid for the activation function, $f\\left(h\\right) = 1/\\left(1+e^{-h}\\right)$\n",
    "\n",
    "And the gradient of the sigmoid is $f'\\left(h\\right) = f\\left(h\\right) \\left(1 - f\\left(h\\right)\\right)$\n",
    "\n",
    "where $h$ is the input to the output unit,\n",
    "\n",
    "$$h = \\sum_i w_i x_i$$\n",
    "\n",
    "### Implementing with Numpy\n",
    "\n",
    "First we need to implement the weights. These need to be small and random, such that they are not symmetric and are fairly flat near zero. So, to do this we will use randomized values from the normal distribution centered about zero. For scale, its good to use $1/\\sqrt(n)$ where $n$ is the number of input units.\n",
    "\n",
    "```weights = np.random.normal(scale=1/n_features**.5, size=n_features)```\n",
    "\n",
    "Now for $h$:\n",
    "\n",
    "```output_in = np.matmul(weights, inputs)```\n",
    "\n",
    "And finally, we can update $\\Delta w_i$ and $w_i$ by incrementing them with `weights += ...` which is shorthand for `weights = weights + ...`.\n",
    "\n",
    "#### data_prep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37f1154a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T05:42:53.142030Z",
     "start_time": "2022-03-30T05:42:53.118122Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "admissions = pd.read_csv('binary.csv')\n",
    "\n",
    "# Make dummy variables for rank\n",
    "data = pd.concat([admissions, pd.get_dummies(admissions['rank'], prefix='rank')], axis=1)\n",
    "data = data.drop('rank', axis=1)\n",
    "\n",
    "# Standarize features\n",
    "for field in ['gre', 'gpa']:\n",
    "    mean, std = data[field].mean(), data[field].std()\n",
    "    data.loc[:,field] = (data[field]-mean)/std\n",
    "    \n",
    "# Split off random 10% of the data for testing\n",
    "np.random.seed(42)\n",
    "sample = np.random.choice(data.index, size=int(len(data)*0.9), replace=False)\n",
    "data, test_data = data.loc[sample], data.drop(sample)\n",
    "\n",
    "# Split into features and targets\n",
    "features, targets = data.drop('admit', axis=1), data['admit']\n",
    "features_test, targets_test = test_data.drop('admit', axis=1), test_data['admit']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89674725",
   "metadata": {},
   "source": [
    "#### gradient.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59e37fc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T05:45:38.057960Z",
     "start_time": "2022-03-30T05:45:36.067441Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.26276093849966364\n",
      "Train loss:  0.20928619409324895\n",
      "Train loss:  0.20084292908073417\n",
      "Train loss:  0.1986215647552789\n",
      "Train loss:  0.19779851396686018\n",
      "Train loss:  0.19742577912189863\n",
      "Train loss:  0.19723507746241065\n",
      "Train loss:  0.19712945625092465\n",
      "Train loss:  0.19706766341315077\n",
      "Train loss:  0.19703005801777368\n",
      "Prediction accuracy: 0.725\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from data_prep import features, targets, features_test, targets_test\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# TODO: We haven't provided the sigmoid_prime function like we did in\n",
    "#       the previous lesson to encourage you to come up with a more\n",
    "#       efficient solution. If you need a hint, check out the comments\n",
    "#       in solution.py from the previous lecture.\n",
    "\n",
    "# Use to same seed to make debugging easier\n",
    "np.random.seed(42)\n",
    "\n",
    "n_records, n_features = features.shape\n",
    "last_loss = None\n",
    "\n",
    "# Initialize weights\n",
    "weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
    "\n",
    "# Neural Network hyperparameters\n",
    "epochs = 1000\n",
    "learnrate = 0.5\n",
    "\n",
    "for e in range(epochs):\n",
    "    del_w = np.zeros(weights.shape)\n",
    "    for x, y in zip(features.values, targets):\n",
    "        # Loop through all records, x is the input, y is the target\n",
    "\n",
    "        # Note: We haven't included the h variable from the previous\n",
    "        #       lesson. You can add it if you want, or you can calculate\n",
    "        #       the h together with the output\n",
    "\n",
    "        # TODO: Calculate the output\n",
    "        h = np.matmul(weights, x)\n",
    "        output = sigmoid(h) # This is y_hat\n",
    "\n",
    "        # TODO: Calculate the error\n",
    "        error = y - output \n",
    "\n",
    "        # TODO: Calculate the error term\n",
    "        error_term = error*output*(1-output) # This is \\delta\n",
    "\n",
    "        # TODO: Calculate the change in weights for this sample\n",
    "        #       and add it to the total weight change\n",
    "        del_w += error_term*x\n",
    "\n",
    "    # TODO: Update weights using the learning rate and the average change in weights\n",
    "    weights += learnrate*del_w/n_records\n",
    "\n",
    "    # Printing out the mean square error on the training set\n",
    "    if e % (epochs / 10) == 0:\n",
    "        out = sigmoid(np.dot(features, weights))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n",
    "\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "tes_out = sigmoid(np.dot(features_test, weights))\n",
    "predictions = tes_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac331c",
   "metadata": {},
   "source": [
    "## Implementing The Hidden Layer\n",
    "\n",
    "Before, we were dealing with only one output node which made the code straightforward. However now that we have multiple input units and multiple hidden units, the weights between them will require two indices: $w_{ij}$ where $i$ denotes input units and $j$ are the hidden units.\n",
    "\n",
    "There is an image of three inputs $x_1, x_2, x_3$ and two hidden layers $h_1, h_2$ feeding the output layer.\n",
    "\n",
    "Now to index the weights, we take the input unit number for the $i$ and the hidden unit number for the $j$. That gives $w_{11}$ for the weight from $x_1$ to $h_1$ and $w_{12}$ for the weight from $x_1$ to $h_2$, for example. \n",
    "\n",
    "Before, we were able to write the weights as an array, indexed as $w_i$. \n",
    "\n",
    "But now, the weights need to be stored in a **matrix**, indexed as $w_{ij}$. Each **row** in the matrix will correspond to the weights **leading out** of a **single input unit**, and each **column** will correspond to the weights **leading in** to a **single hidden unit**. For our three input units and two hidden units, the weights matrix looks like this:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "w_{11} & w_{12}\\\\\n",
    "w_{21} & w_{22}\\\\\n",
    "w_{31} & w_{32}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "To initialize these weights in NumPy, we have to provide the shape of the matrix. If `features` is a 2D array containing the input data:\n",
    "\n",
    "```\n",
    "# Number of records and input units\n",
    "n_records, n_inputs = features.shape\n",
    "# Number of hidden units\n",
    "n_hidden = 2\n",
    "weights_input_to_hidden = np.random.normal(0, n_inputs**-0.5, size=(n_inputs, n_hidden))\n",
    "```\n",
    "\n",
    "Now that we have a matrix of the correct size, `n_inputs` by `n_hidden`, we need to calculate the hidden layer values $h_j$:\n",
    "\n",
    "$$\n",
    "h_j = \\sum_i w_{ij} x_i\n",
    "$$\n",
    "\n",
    "To calculate this, we use matrix multiplication:\n",
    "\n",
    "$$\n",
    "\\left[x_1 \\ x_2 \\ x_3 \\right] \\times \\left[\\begin{array}{ccc}\n",
    "  w_{11} & w_{12} \\\\\n",
    "  w_{21} & w_{22} \\\\\n",
    "  w_{31} & w_{32} \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "So for example $h_1$ would be:\n",
    "\n",
    "$$\n",
    "h_1 = x_1 w_{11} + x_2 w_{21} + x_3 w_{31}\n",
    "$$\n",
    "\n",
    "In NumPy, you can do this for all the inputs and all the outputs at once using `np.matmul`:\n",
    "\n",
    "`\n",
    "hidden_inputs = np.matmul(inputs, weights_input_to_hidden)\n",
    "`\n",
    "### Quiz\n",
    "\n",
    "Below, you'll implement a forward pass through a 4x3x2 network, with sigmoid activation functions for both layers.\n",
    "\n",
    "Things to do:\n",
    "\n",
    "- Calculate the input to the hidden layer.\n",
    "- Calculate the hidden layer output.\n",
    "- Calculate the input to the output layer.\n",
    "- Calculate the output of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d31b70d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T07:52:15.930899Z",
     "start_time": "2022-03-30T07:52:15.907452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden-layer Output:\n",
      "[0.41492192 0.42604313 0.5002434 ]\n",
      "Output-layer Output:\n",
      "[0.49815196 0.48539772]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Network size\n",
    "N_input = 4\n",
    "N_hidden = 3\n",
    "N_output = 2\n",
    "\n",
    "np.random.seed(42)\n",
    "# Make some fake data\n",
    "X = np.random.randn(4)\n",
    "\n",
    "weights_input_to_hidden = np.random.normal(0, scale=0.1, size=(N_input, N_hidden))\n",
    "weights_hidden_to_output = np.random.normal(0, scale=0.1, size=(N_hidden, N_output))\n",
    "\n",
    "\n",
    "# TODO: Make a forward pass through the network\n",
    "\n",
    "hidden_layer_in = np.matmul(X, weights_input_to_hidden)\n",
    "hidden_layer_out = sigmoid(hidden_layer_in)\n",
    "\n",
    "print('Hidden-layer Output:')\n",
    "print(hidden_layer_out)\n",
    "\n",
    "output_layer_in = np.matmul(hidden_layer_out, weights_hidden_to_output)\n",
    "output_layer_out = sigmoid(output_layer_in)\n",
    "\n",
    "print('Output-layer Output:')\n",
    "print(output_layer_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ee031e",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "To update the weights to hidden layers using gradient descent, you need to know how much error each of the hidden units contributed to the final output. Since the output of a layer is determined by the weights between layers, the error resulting from units is scaled by the weights going forward through the network. Since we know the error at the output, we can use the weights to work backwards to hidden layers.\n",
    "\n",
    "For example, in the output layer, you have errors $\\delta^o_k$ attributed to each output unit $k$. Then, the error attributed to hidden unit $j$ is the output errors, scaled by the weights between the output and hidden layers (and the gradient):\n",
    "\n",
    "$$\n",
    "\\delta^h_j = \\sum W_{jk} \\delta^o_k f'\\left(h_j\\right)\n",
    "$$\n",
    "\n",
    "Where $\\delta^o$ is the error term of the *output*. Then, the gradient descent step is the same as before, just with the new errors:\n",
    "\n",
    "$$\n",
    "\\Delta w_{ij} = \\eta \\delta^h_j x_i\n",
    "$$\n",
    "\n",
    "where $w_{ij}$ are the weights between the inputs and hidden layer and $x_i$ are input unit values. The weight steps are equal to the step size times the output error of the layer times the values of the inputs to that layer:\n",
    "\n",
    "$$\n",
    "\\Delta w_{pq} = \\eta \\delta_{output} V_{in}\n",
    "$$\n",
    "\n",
    "Here, you get the output error, $\\delta_{output}$ by propagating the errors backwards from higher layers. And the input values, $V_{in}$ are the inputs to the layer, the hidden layer activations to the output unit for example.\n",
    "\n",
    "### Implementing in Numpy\n",
    "\n",
    "previously we were only dealing with error terms from one unit. Now, in the weight update, we have to consider the error for each unit in the hidden layer, $\\delta_j$ \n",
    "\n",
    "$$\n",
    "\\Delta w_{ij} = \\eta \\delta_j x_i\n",
    "$$\n",
    "\n",
    "As $w_{ij}$ is a matrix now, so the right side of the assignment must have the same shape as the left side. \n",
    "\n",
    "```\n",
    "# inputs is 1D here\n",
    "hidden_error*inputs[:,None]\n",
    "array([[ -8.24195994e-04,  -2.71771975e-04,   1.29713395e-03],\n",
    "       [ -2.87777394e-04,  -9.48922722e-05,   4.52909055e-04],\n",
    "       [  6.44605731e-04,   2.12553536e-04,  -1.01449168e-03],\n",
    "       [  0.00000000e+00,   0.00000000e+00,  -0.00000000e+00],\n",
    "       [  0.00000000e+00,   0.00000000e+00,  -0.00000000e+00],\n",
    "       [  0.00000000e+00,   0.00000000e+00,  -0.00000000e+00]])\n",
    "```\n",
    "\n",
    "It turns out this is exactly how we want to calculate the weight update step. As before, if you have your inputs as a 2D array with one row, you can also do `hidden_error*inputs.T`, but that won't work if `inputs` is a 1D array.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Below, you'll implement the code to calculate one backpropagation update step for two sets of weights. I wrote the forward pass - your goal is to code the backward pass.\n",
    "\n",
    "Things to do\n",
    "\n",
    "- Calculate the network's output error.\n",
    "- Calculate the output layer's error term.\n",
    "- Use backpropagation to calculate the hidden layer's error term.\n",
    "- Calculate the change in weights (the delta weights) that result from propagating the errors back through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "311697b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-31T20:12:22.539233Z",
     "start_time": "2022-03-31T20:12:22.487547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in weights for hidden layer to output layer:\n",
      "[0.00804047 0.00555918]\n",
      "Change in weights for input layer to hidden layer:\n",
      "[[ 1.77005547e-04 -5.11178506e-04]\n",
      " [ 3.54011093e-05 -1.02235701e-04]\n",
      " [-7.08022187e-05  2.04471402e-04]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "x = np.array([0.5, 0.1, -0.2])\n",
    "target = 0.6\n",
    "learnrate = 0.5\n",
    "\n",
    "weights_input_hidden = np.array([[0.5, -0.6],\n",
    "                                 [0.1, -0.2],\n",
    "                                 [0.1, 0.7]])\n",
    "\n",
    "weights_hidden_output = np.array([0.1, -0.3])\n",
    "\n",
    "## Forward pass\n",
    "hidden_layer_input = np.dot(x, weights_input_hidden)\n",
    "hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\n",
    "output = sigmoid(output_layer_in)\n",
    "\n",
    "## Backwards pass\n",
    "## TODO: Calculate output error\n",
    "error = target - output\n",
    "\n",
    "# TODO: Calculate error term for output layer\n",
    "output_error_term = error*output*(1-output)\n",
    "\n",
    "# TODO: Calculate error term for hidden layer\n",
    "hidden_error_term = np.dot(output_error_term,weights_hidden_output)*hidden_layer_output*(1-hidden_layer_output)\n",
    "\n",
    "# TODO: Calculate change in weights for hidden layer to output layer\n",
    "delta_w_h_o = learnrate*output_error_term*hidden_layer_output\n",
    "\n",
    "# TODO: Calculate change in weights for input layer to hidden layer\n",
    "delta_w_i_h = learnrate*hidden_error_term*x[:,None]\n",
    "\n",
    "print('Change in weights for hidden layer to output layer:')\n",
    "print(delta_w_h_o)\n",
    "print('Change in weights for input layer to hidden layer:')\n",
    "print(delta_w_i_h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d70559e",
   "metadata": {},
   "source": [
    "## Implementing Backpropagation\n",
    "\n",
    "Error term of output layer:\n",
    "\n",
    "$$\n",
    "\\delta_k = \\left(y_k - \\hat{y}_k \\right) f'\\left(a_k\\right)\n",
    "$$\n",
    "\n",
    "and the error term of the hidden layer is:\n",
    "\n",
    "$$\n",
    "\\delta_j = \\sum \\left[w_{jk} \\delta_k \\right] f'(h_j)\n",
    "$$\n",
    "\n",
    "For now we'll just consider a simple network with one hidden layer. In general, here is the algorithm for updating the weights with backpropagation:\n",
    "\n",
    "- Set the weight steps for each layer to zero\n",
    "  - The input to hidden weights $\\Delta w_{ij} = 0$\n",
    "  - The hidden to output weights $\\Delta W_j = 0$\n",
    "- For each record in the training data:\n",
    "  - Make a forward pass through the network, calculating the output $\\hat{y}$\n",
    "  - Calculate the error gradient in the output unit, $\\delta^o = \\left(y - \\hat{y} \\right) f'(z)$ where $z = \\sum_j W_j a_j$, the input to the output unit.\n",
    "  - Propagate the errors to the hidden layer $\\delta^h_j = \\delta^o W_j f'(h_j)$\n",
    "  - Update the weight steps:\n",
    "    - $\\Delta W_j = \\Delta W_j + \\delta^o a_j$\n",
    "    - $\\Delta w_{ij} = \\Delta w_{ij} + \\delta^h_j a_i$\n",
    "- Update the weights, where $\\eta$ is the learning rate and $m$ is the number of records:\n",
    "  - $W_j = W_j + \\eta\\Delta W_j/m$\n",
    "  - $w_{ij} = w_{ij} + \\eta\\Delta w_{ij} / m$\n",
    "- Repeat for $e$ epochs.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Now you're going to implement the `backprop` algorithm for a network trained on the graduate school admission data. You should have everything you need from the previous exercises to complete this one.\n",
    "\n",
    "Your goals here:\n",
    "\n",
    "- Implement the forward pass.\n",
    "- Implement the backpropagation algorithm.\n",
    "- Update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7af81109",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-31T20:54:44.681646Z",
     "start_time": "2022-03-31T20:54:44.631478Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_prep.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "admissions = pd.read_csv('binary.csv')\n",
    "\n",
    "# Make dummy variables for rank\n",
    "data = pd.concat([admissions, pd.get_dummies(admissions['rank'], prefix='rank')], axis=1)\n",
    "data = data.drop('rank', axis=1)\n",
    "\n",
    "# Standarize features\n",
    "for field in ['gre', 'gpa']:\n",
    "    mean, std = data[field].mean(), data[field].std()\n",
    "    data.loc[:,field] = (data[field]-mean)/std\n",
    "    \n",
    "# Split off random 10% of the data for testing\n",
    "np.random.seed(21)\n",
    "sample = np.random.choice(data.index, size=int(len(data)*0.9), replace=False)\n",
    "data, test_data = data.loc[sample], data.drop(sample)\n",
    "\n",
    "# Split into features and targets\n",
    "features, targets = data.drop('admit', axis=1), data['admit']\n",
    "features_test, targets_test = test_data.drop('admit', axis=1), test_data['admit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c014705",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-31T21:47:39.940677Z",
     "start_time": "2022-03-31T21:47:36.079067Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.2513415251760966\n",
      "Train loss:  0.24949668820558593\n",
      "Train loss:  0.24773374212983035\n",
      "Train loss:  0.2460497263842906\n",
      "Train loss:  0.24444172473542344\n",
      "Train loss:  0.24290687239038056\n",
      "Train loss:  0.24144236202964173\n",
      "Train loss:  0.24004544885203738\n",
      "Train loss:  0.23871345471874167\n",
      "Train loss:  0.23744377147939685\n",
      "Prediction accuracy: 0.750\n"
     ]
    }
   ],
   "source": [
    "# backprop.py\n",
    "\n",
    "#import numpy as np\n",
    "#from data_prep import features, targets, features_test, targets_test\n",
    "\n",
    "np.random.seed(21)\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "n_hidden = 2  # number of hidden units\n",
    "epochs = 600\n",
    "learnrate = 0.01\n",
    "\n",
    "n_records, n_features = features.shape\n",
    "last_loss = None\n",
    "# Initialize weights\n",
    "weights_input_hidden = np.random.normal(scale=1 / n_features ** .5,\n",
    "                                        size=(n_features, n_hidden))\n",
    "weights_hidden_output = np.random.normal(scale=1 / n_features ** .5,\n",
    "                                         size=n_hidden)\n",
    "\n",
    "for e in range(epochs):\n",
    "    del_w_input_hidden = np.zeros(weights_input_hidden.shape)\n",
    "    del_w_hidden_output = np.zeros(weights_hidden_output.shape)\n",
    "    for x, y in zip(features.values, targets):\n",
    "        ## Forward pass ##\n",
    "        # TODO: Calculate the output\n",
    "        hidden_input = np.dot(x, weights_input_hidden)\n",
    "        hidden_output = sigmoid(hidden_input)\n",
    "        output = sigmoid(np.dot(hidden_output, weights_hidden_output))\n",
    "\n",
    "        ## Backward pass ##\n",
    "        # TODO: Calculate the network's prediction error\n",
    "        error = y - output\n",
    "\n",
    "        # TODO: Calculate error term for the output unit\n",
    "        output_error_term = error*output*(1-output)\n",
    "\n",
    "        ## propagate errors to hidden layer\n",
    "\n",
    "        # TODO: Calculate the hidden layer's contribution to the error\n",
    "        hidden_error = np.dot(output_error_term,weights_hidden_output)\n",
    "        \n",
    "        # TODO: Calculate the error term for the hidden layer\n",
    "        hidden_error_term = hidden_error*hidden_output*(1-hidden_output)\n",
    "        \n",
    "        # TODO: Update the change in weights\n",
    "        del_w_hidden_output += output_error_term*hidden_output\n",
    "        del_w_input_hidden += hidden_error_term*x[:,None]\n",
    "\n",
    "    # TODO: Update weights  (don't forget to division by n_records or number of samples)\n",
    "    weights_input_hidden += learnrate*del_w_input_hidden/n_records\n",
    "    weights_hidden_output += learnrate*del_w_hidden_output/n_records\n",
    "\n",
    "    # Printing out the mean square error on the training set\n",
    "    if e % (epochs / 10) == 0:\n",
    "        hidden_output = sigmoid(np.dot(x, weights_input_hidden))\n",
    "        out = sigmoid(np.dot(hidden_output,\n",
    "                             weights_hidden_output))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "hidden = sigmoid(np.dot(features_test, weights_input_hidden))\n",
    "out = sigmoid(np.dot(hidden, weights_hidden_output))\n",
    "predictions = out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c495f73c",
   "metadata": {},
   "source": [
    "# Lesson 3: Training Neural Networks\n",
    "\n",
    "It's time to dive into **optimizing the training on our models**. Here we will be able to:\n",
    "\n",
    "- Separate data into testing and training sets in order to objectively test a model and ensure that it can generalize beyond the training data.\n",
    "- Distinguish between underfitting and overfitting, and identify the underlying causes of each.\n",
    "- Use early stopping to end the training process at a point that minimizes both testing error and training error.\n",
    "- Apply regularization to reduce overfitting.\n",
    "- Use dropout to randomly turn off portions of a network during training and ensure no single part of the network dominates the resulting model disproportionately.\n",
    "- Use random restart to avoid getting stuck in local minima.\n",
    "- Use the hyperbolic tangent function and ReLU to improve gradient descent.\n",
    "- Distinguish between batch gradient descent vs stochastic gradient descent.\n",
    "- Adjust the learning rate of the gradient descent algorithm in order to improve model optimization.\n",
    "- Use momentum to avoid getting stuck in local minima.\n",
    "\n",
    "## Training and Testing\n",
    "\n",
    "We can split data into *training* and *testing* sets to have a way of objectively testing our models. \n",
    "\n",
    "While training, we only use the training data â€” we set the testing data aside and don't use it as input for our learning algorithm.\n",
    "\n",
    "Then, once our models are trained, we reintroduce the testing set. A model that performs well on the training data may not perform well on the testing data. We'll see one reason for this, called overfitting, next.\n",
    "\n",
    "## Overfitting and Underfitting\n",
    "\n",
    "When we train our models, it is entirely possible to get them to a point where they perform very well on our training data â€” but then perform very poorly on our testing data. Two common reasons for this are **underfitting** and **overfitting**.\n",
    "\n",
    "### Underfitting\n",
    "\n",
    "- Underfitting means that our model is too simplistic. There is a poor fit between our model and the data because we have **oversimplified** the problem.\n",
    "- Underfitting is sometimes referred to as **error due to bias**. Our training data may be biased and this bias may be incorporated into the model in a way that oversimplifies it.\n",
    "\n",
    "### Overfitting\n",
    "\n",
    "- Overfitting means that our model is too complicated. The fit between our model and the training data is **too specific** â€” the model will perform very well on the training data but will **fail to generalize** to new data.\n",
    "- Overfitting is sometimes referred to as **error due to variance**. This means that there are random or irrelevant differences among the data points in our training data and we have fit the model so closely to these irrelevant differences that it performs poorly when we try to use it with our testing data.\n",
    "\n",
    "## Early Stopping\n",
    "\n",
    "When training our neural network, we start with random weights in the first epoch and then change these weights as we go through additional epochs. Initially, we expect these changes to improve our model as the neural network fits the training data more closely. But after some time, further changes will start to result in overfitting.\n",
    "\n",
    "We can monitor this by measuring both the training error and the testing error. As we train the network, the training error will go down â€” but at some point, the testing error will start to increase. This indicates overfitting and is a signal that we should stop training the network prior to that point.\n",
    "\n",
    "In summary, we do gradient descent until the testing error stops decreasing and starts to increase. At that moment, we stop. This algorithm is called **early stopping** and is widely used to train neural networks.\n",
    "\n",
    "## Regularization\n",
    "\n",
    "Now the question is, how do we prevent overfitting from happening? The trouble is that large coefficients are leading to overfitting, so what we need to do is adjust our error function by, essentially, penalizing large weights.\n",
    "\n",
    "Recall, our original error function looks like this:\n",
    "\n",
    "$$\n",
    "-\\frac{1}{m} \\sum_{i=1}^{m} \\left(1-y_i\\right)\\ln\\left(1-\\hat{y}_i\\right) + y_i \\ln\\left(\\hat{y}_i\\right)\n",
    "$$\n",
    "\n",
    "Need to add a term that is large when the weights are large. The two options that are most widely used are:\n",
    "\n",
    "1. Sums of absolute values\n",
    "$$\n",
    "+\\lambda\\left(|w_1| + \\ ... \\ + |w_n|\\right)\n",
    "$$\n",
    "\n",
    "2. Sums of Squares\n",
    "\n",
    "$$\n",
    "+\\lambda\\left(w_1^2 + \\ ... \\ + w_n^2 \\right)\n",
    "$$\n",
    "\n",
    "### L1 vs L2 Regularization\n",
    "\n",
    "These two approaches are labeled as **L1** (absolute values) and **L2** (squares) regularization apiece. There are differences, pros and cons, for each:\n",
    "\n",
    "#### L1 Regularization\n",
    "\n",
    "- L1 tends to result in sparse vectors. That means small weights will tend to go to zero.\n",
    "- If we want to reduce the number of weights and end up with a small set, we can use L1.\n",
    "- L1 is also good for feature selection. Sometimes we have a problem with hundreds of features, and L1 regularization will help us select which ones are important, turning the rest into zeroes.\n",
    "\n",
    "#### L2 Regularization\n",
    "\n",
    "- L2 tends not to favor sparse vectors since it tries to maintain all the weights homogeneously small.\n",
    "- L2 gives better results for training models so it's the one we'll use the most.\n",
    "\n",
    "## Dropout\n",
    "\n",
    "In **dropout**, we turn part of the network off and let the rest of the network train:\n",
    "\n",
    "- We go through the epochs and randomly turn off some of the nodes. This forces the other nodes to pick up the slack and take a larger part in the training.\n",
    "- To drop nodes, we give the algorithm a parameter that indicates the probability that each node will get dropped during each epoch. For example, if we set this parameter to 0.2, this means that during each epoch, each node has a 20% probability of being turned off.\n",
    "- Note that some nodes may get turned off more than others and some may never get turned off. This is OK since we're doing it over and over; on average, each node will get approximately the same treatment.\n",
    "\n",
    "## Random Restart\n",
    "\n",
    "This is basically starting, then restarting, at a few different random places for the GD, with the goal of eventually finding the best local minimum, or the global minimum. \n",
    "\n",
    "## Other Activation Functions\n",
    "\n",
    "The sigmoid function, while very useful, has some notable flaws. For example, as we get further from the origin, the slope approaches zero, and thus the gradient approaches zero. This is known as the **vanishing gradient problem**. \n",
    "\n",
    "More formally, \n",
    "\n",
    "- The sigmoid curve gets pretty flat on the sides, so if we calculate the derivative at a point far to the right or far to the left, this derivative is almost zero.\n",
    "- This is problematic because it is the derivative that tells us what direction to move in. This is especially problematic in most linear perceptrons.\n",
    "\n",
    "### Hyperbolic Tangent\n",
    "\n",
    "$$\n",
    "\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n",
    "$$\n",
    "\n",
    "Since the y-axis range of this function is from 1 to -1, our derivatives increase and the training accuracy is boosted.\n",
    "\n",
    "### Rectified Linear Unit (ReLU)\n",
    "\n",
    "$$\n",
    "\\text{relu}(x) = \\begin{cases}\n",
    "    x & \\text{if} \\ x \\ge 0 \\\\\n",
    "    0 & \\text{if} \\ x < 0\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "In other words:\n",
    "\n",
    "- If the input is positive, return the same value.\n",
    "- If the input is negative, return zero.\n",
    "\n",
    "This function is used a lot instead of the sigmoid and it can improve the training significantly without sacrificing much accuracy (since the derivative is one if the number is positive).\n",
    "\n",
    "## Batch vs Stochastic Gradient Descent\n",
    "\n",
    "### Batch GD\n",
    "\n",
    "First, let's review our **batch gradient descent** algorithm:\n",
    "\n",
    "- In order to decrease error, we take a bunch of steps following the negative of the gradient, which is the error function.\n",
    "- Each step is called an epoch.\n",
    "- In each epoch, we take our input (all of our data) and run it through the entire neural network.\n",
    "- Then we find our predictions and calculate the error (how far the predictions are from the actual labels).\n",
    "- Finally, we back-propagate this error in order to update the weights in the neural network. This will give us a better boundary for predicting our data.\n",
    "\n",
    "If we have a large number of data points then this process will involve huge matrix computations, which would use a lot of memory.\n",
    "\n",
    "### Stochastic GD\n",
    "\n",
    "To expedite this, we can use only *some* of our data at each step. If the data is well-distributed then a subset of the data can give us enough information about the gradient.\n",
    "\n",
    "This is the idea behind **stochastic gradient descent**. We take small subsets of the data and run them through the neural network, calculating the gradient of the error function based on these points and moving one step in that direction.\n",
    "\n",
    "We still want to use all our data, so what we do is the following:\n",
    "\n",
    "- Split the data into several batches.\n",
    "- Take the points in the first batch and run them through the neural network.\n",
    "- Calculate the error and its gradient.\n",
    "- Back-propagate to update the weights (which will define a better boundary region).\n",
    "- Repeat the above steps for the rest of the batches.\n",
    "\n",
    "Notice that with this approach we take multiple steps, whereas with batch gradient descent we take only one step with all the data. Each step may be less accurate, but, in practice, it's much better to take a bunch of slightly inaccurate steps than to take only one good one.\n",
    "\n",
    "## Learning Rate Decay\n",
    "\n",
    "In general, if a learning rate is too high, then we will not be able to land properly in a local minimum. But if it is too low, then it can be too slow. However, low tends to be better than high, and a rule of thumb is that if your model isn't working, try decreasing the learning rate.\n",
    "\n",
    "The best learning rates, though, are those that decrease as the algorithm gets closer to the solution.\n",
    "\n",
    "## Momentum\n",
    "\n",
    "Momentum can be used to help get us past local minimum and \"over the hump\" so to speak. We use $\\beta$ as the momentum constant, with $0\\le \\beta \\ge 1$.\n",
    "\n",
    "We want to use this momentum to generate a weighted average of the previous steps:\n",
    "\n",
    "$$\n",
    "\\text{step}(n) + \\beta \\text{step}(n-1) + \\beta^2 \\text{step}(n) + \\beta^3 (n-2) + \\ ...\n",
    "$$\n",
    "\n",
    " Because $\\beta$ has a value between $0$ and $1$, raising it to increasingly large powers means that the value will get smaller and smaller. In this way, the steps that happened a long time ago will be multiplied by tiny values and thus matter less than the ones that happened recently.\n",
    "\n",
    "This can get us over \"humps\" and help us discover better minima. Once we get to the global minimum, the momentum will still be pushing us away, but not as much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb36e90",
   "metadata": {},
   "source": [
    "# Lesson 5: Sentiment Analysis\n",
    "\n",
    "## Trask NN Lectures supplimentary info.\n",
    "\n",
    "In his video he initialized the weights using `output_nodes**0.5`, but it turns out that we can get better results faster by using `hidden_nodes**0.5` to initialize the weights. This allows the NN to start to increase accuracy with a larger learning rate, i.e. `0.01` instead of `0.001` like we had to use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
